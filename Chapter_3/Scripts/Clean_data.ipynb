{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1738913661580,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "DRDtS8bl1b6h"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re, os\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "import hashlib\n",
    "import difflib\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1738874042446,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "of3S5kZR9r-J",
    "outputId": "e4b684e8-347d-4e0c-af69-0169a2c6bcd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary NLTK components are available\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1738875880137,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "7nMn8UkF-DP0"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_text(text):\n",
    "   text = text.lower()  # Convert to lowercase\n",
    "   text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
    "   text = re.sub(r'[^\\w\\s.%]', '', text)  # Remove special characters except percentages\n",
    "   text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "   return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1738875887117,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "e518xxq8-oFv",
    "outputId": "ad444ef2-679a-4f68-843e-a08c943e6d63"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'stock prices surged by 5% today'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = \"<p>Stock prices <b>surged</b> by 5% today!</p>\"\n",
    "clean_text(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1738875894670,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "3MLrgKSa_HzL",
    "outputId": "978eb5e6-d651-4cc7-cd3e-5ef22e2e434e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'teslas earnings report betterthanexpected'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_2 = \"Tesla's earnings report: **better-than-expected**!  ðŸš€ðŸš€\"\n",
    "clean_text(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1738876053929,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "61z-w3XX_P8V",
    "outputId": "2916d78a-2626-46d9-d063-3986ef175a37"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'the market is volatile prices dropped 10%.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_3 = \"<div> The market   is volatile!!! Prices dropped 10%.  </div>\"\n",
    "clean_text(input_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdHSvXklBTkG"
   },
   "outputs": [],
   "source": [
    "def impute_missing_data(df):\n",
    "  df['published_date'].fillna('1980-01-01', inplace=True)  # Default for missing dates\n",
    "  df['source'].fillna('Unknown', inplace=True)\n",
    "  df['summary'].fillna('No Summary Available', inplace=True)\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2karv2DhKfIC"
   },
   "source": [
    "The following test script provides the comparison of the input before imputation and after imputation. Though the code is standardised, dates imputed with the string value 'Unknown' should be validated with date type for downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1738876990794,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "RNIsgFx5GZcw",
    "outputId": "b963189a-4e88-43a3-9e00-ecb2270fb2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Before Imputation ===\n",
      "  published_date     source                                            summary\n",
      "0     2024-02-01    Reuters  Stock prices surged after strong earnings report.\n",
      "1     2024-02-02  Bloomberg  Market remains stable despite geopolitical ten...\n",
      "2     2024-02-03       CNBC  Investors optimistic about the tech sectorâ€™s g...\n",
      "3           None       None                                               None\n",
      "4           None     Forbes  Earnings decline could lead to a market downturn.\n",
      "5     2024-02-06       None                                               None\n",
      "\n",
      "=== After Imputation ===\n",
      "  published_date     source  \\\n",
      "0     2024-02-01    Reuters   \n",
      "1     2024-02-02  Bloomberg   \n",
      "2     2024-02-03       CNBC   \n",
      "3        Unknown    Unknown   \n",
      "4        Unknown     Forbes   \n",
      "5     2024-02-06    Unknown   \n",
      "\n",
      "                                             summary  sentiment_before  \\\n",
      "0  Stock prices surged after strong earnings report.            0.5106   \n",
      "1  Market remains stable despite geopolitical ten...            0.5358   \n",
      "2  Investors optimistic about the tech sectorâ€™s g...            0.5994   \n",
      "3                               No Summary Available               NaN   \n",
      "4  Earnings decline could lead to a market downturn.            0.0000   \n",
      "5                               No Summary Available               NaN   \n",
      "\n",
      "   sentiment_after  \n",
      "0           0.5106  \n",
      "1           0.5358  \n",
      "2           0.5994  \n",
      "3          -0.2960  \n",
      "4           0.0000  \n",
      "5          -0.2960  \n",
      "\n",
      "=== Sentiment Score Comparison ===\n",
      "Row 1: Before = 0.5106, After = 0.5106\n",
      "Row 2: Before = 0.5358, After = 0.5358\n",
      "Row 3: Before = 0.5994, After = 0.5994\n",
      "Row 4: Before = nan, After = -0.296\n",
      "Row 5: Before = 0.0, After = 0.0\n",
      "Row 6: Before = nan, After = -0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2ded6c499d88>:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['published_date'].fillna('Unknown', inplace=True)  # Default for missing dates\n",
      "<ipython-input-14-2ded6c499d88>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['source'].fillna('Unknown', inplace=True)\n",
      "<ipython-input-14-2ded6c499d88>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['summary'].fillna('No Summary Available', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample data:\n",
    "# published_data have 2 missing dates\n",
    "# source column have 2 missing values\n",
    "# summary column has two missing summaries\n",
    "data = {\n",
    "    'published_date': ['2024-02-01', '2024-02-02', '2024-02-03', None, None, '2024-02-06'],\n",
    "    'source': ['Reuters', 'Bloomberg', 'CNBC', None, 'Forbes', None],\n",
    "    'summary': [\n",
    "        \"Stock prices surged after strong earnings report.\",\n",
    "        \"Market remains stable despite geopolitical tensions.\",\n",
    "        \"Investors optimistic about the tech sectorâ€™s growth.\",\n",
    "        None,  # Missing summary\n",
    "        \"Earnings decline could lead to a market downturn.\",  # Negative sentiment\n",
    "        None  # Missing summary\n",
    "    ]\n",
    "}\n",
    "\n",
    "# create a pandas dataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print raw data\n",
    "print(\"\\n=== Before Imputation ===\")\n",
    "print(df)\n",
    "\n",
    "# Sentiment Analysis Before Imputation\n",
    "df['sentiment_before'] = df['summary'].apply(lambda x: sia.polarity_scores(x)['compound'] if pd.notna(x) else None)\n",
    "\n",
    "# Apply Imputation Function\n",
    "df = impute_missing_data(df)\n",
    "\n",
    "# Sentiment Analysis After Imputation\n",
    "df['sentiment_after'] = df['summary'].apply(lambda x: sia.polarity_scores(x)['compound'] if pd.notna(x) else None)\n",
    "\n",
    "# Print cleaned data\n",
    "print(\"\\n=== After Imputation ===\")\n",
    "print(df)\n",
    "\n",
    "# Show impact on sentiment analysis\n",
    "print(\"\\n=== Sentiment Score Comparison ===\")\n",
    "for i in range(len(df)):\n",
    "    print(f\"Row {i+1}: Before = {df['sentiment_before'][i]}, After = {df['sentiment_after'][i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWbshSvudvy7"
   },
   "source": [
    "Detect Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1738883758307,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "8m0QaSsDdulA",
    "outputId": "41c074b5-5bf3-4788-8a25-0d739a9b525a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Distribution: Counter({'Bloomberg': 1, 'Reuters': 1, 'CNBC': 1, 'Forbes': 1, 'Unknown': 1, 'YahooFinance': 1})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a dictionary with credibility scores for different sources\n",
    "#  following credibility scores are arbitrarily assigned for the purpose of example only\n",
    "\n",
    "SOURCE_CREDIBILITY = {\"Reuters\": 5, \"Bloomberg\": 5, \"CNBC\": 4, \"Financial   Times\": 4, \"Forbes\": 3,\"YahooFinance\": 3, \"Unknown\": 0 }\n",
    "def detect_bias(df):\n",
    "    source_counts = Counter(df['source'])\n",
    "    print(\"Source Distribution:\", source_counts)\n",
    "    return df\n",
    "\n",
    "# Sample dataset with different sources\n",
    "data = {\n",
    "    'published_date': ['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06'],\n",
    "    'source': ['Bloomberg', 'Reuters', 'CNBC', 'Forbes', 'Unknown', 'YahooFinance'],\n",
    "    'summary': [\n",
    "        \"Stock prices surged after strong earnings report.\",\n",
    "        \"Market remains stable despite geopolitical tensions.\",\n",
    "        \"Investors optimistic about the tech sectorâ€™s growth.\",\n",
    "        \"Rumors about Apple launching a new product soon.\",\n",
    "        \"A random blog claims market crash incoming!\",\n",
    "        \"Crypto community is discussing Bitcoin's price surge.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply credibility scoring function\n",
    "df = detect_bias(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu0GeMVtpvSW"
   },
   "source": [
    "Contextual Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6598,
     "status": "ok",
     "timestamp": 1738885424328,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "n_Ars95vmY__",
    "outputId": "48923295-4e5f-41c4-da66-a878b06b5d56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sentiment Analysis Test Cases ===\n",
      "Test 1: Apple stock surges 10% after record-breaking earnings report.\n",
      "   â†’ Sentiment: positive, Confidence: 0.8603\n",
      "\n",
      "Test 2: The stock market remains stable despite recent fluctuations.\n",
      "   â†’ Sentiment: positive, Confidence: 0.8533\n",
      "\n",
      "Test 3: Tesla shares plummet 15% due to declining revenue and supply chain issues.\n",
      "   â†’ Sentiment: negative, Confidence: 0.9712\n",
      "\n",
      "Test 4: Gold prices remain unchanged amid mixed economic data.\n",
      "   â†’ Sentiment: negative, Confidence: 0.6643\n",
      "\n",
      "Test 5: Some analysts predict a possible stock market crash.\n",
      "   â†’ Sentiment: negative, Confidence: 0.9347\n",
      "\n",
      "Test 6: Rumors suggest the Federal Reserve might cut interest rates soon.\n",
      "   â†’ Sentiment: negative, Confidence: 0.8753\n",
      "\n",
      "Test 7: Despite poor earnings, the company expects strong growth next year.\n",
      "   â†’ Sentiment: positive, Confidence: 0.9344\n",
      "\n",
      "Test 8: NASDAQ sees a bullish trend as S&P 500 reaches a new high.\n",
      "   â†’ Sentiment: positive, Confidence: 0.8942\n",
      "\n",
      "Test 9: I love hiking in the mountains during weekends.\n",
      "   â†’ Sentiment: neutral, Confidence: 0.8918\n",
      "\n",
      "Test 10: \n",
      "   â†’ Sentiment: Neutral, Confidence: 0.0000\n",
      "\n",
      "Test 11: Profits\n",
      "   â†’ Sentiment: neutral, Confidence: 0.7536\n",
      "\n",
      "Test 12: Stock price up 3.5%!!! ðŸ”¥ðŸ”¥ðŸ”¥\n",
      "   â†’ Sentiment: positive, Confidence: 0.9291\n",
      "\n",
      "Test 13: Las acciones de Tesla suben un 5%.\n",
      "   â†’ Sentiment: neutral, Confidence: 0.9002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the contextual sentiment analysis model\n",
    "contextual_analyzer = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "def contextual_sentiment_analysis(text):\n",
    "    if not text or not isinstance(text, str):  # Handle empty and non-string inputs\n",
    "        return \"Neutral\", 0.0\n",
    "    result = contextual_analyzer(text)\n",
    "    sentiment_label = result[0]['label']\n",
    "    confidence = result[0]['score']\n",
    "    return sentiment_label, confidence\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"Apple stock surges 10% after record-breaking earnings report.\",  # Positive\n",
    "    \"The stock market remains stable despite recent fluctuations.\",  # Neutral/Positive\n",
    "    \"Tesla shares plummet 15% due to declining revenue and supply chain issues.\",  # Negative\n",
    "    \"Gold prices remain unchanged amid mixed economic data.\",  # Neutral\n",
    "    \"Some analysts predict a possible stock market crash.\",  # Neutral/Negative\n",
    "    \"Rumors suggest the Federal Reserve might cut interest rates soon.\",  # Neutral\n",
    "    \"Despite poor earnings, the company expects strong growth next year.\",  # Neutral\n",
    "    \"NASDAQ sees a bullish trend as S&P 500 reaches a new high.\",  # Positive\n",
    "    \"I love hiking in the mountains during weekends.\",  # Non-financial, should be Neutral\n",
    "    \"\",  # Edge case: Empty input\n",
    "    \"Profits\",  # Edge case: Single word\n",
    "    \"Stock price up 3.5%!!! ðŸ”¥ðŸ”¥ðŸ”¥\",  # Handling special characters and numbers\n",
    "    \"Las acciones de Tesla suben un 5%.\"  # Non-English text\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "print(\"\\n=== Sentiment Analysis Test Cases ===\")\n",
    "for i, text in enumerate(test_cases):\n",
    "    sentiment, confidence = contextual_sentiment_analysis(text)\n",
    "    print(f\"Test {i+1}: {text}\")\n",
    "    print(f\"   â†’ Sentiment: {sentiment}, Confidence: {confidence:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9A0moWCDiuF"
   },
   "source": [
    "Extracting numerical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1738909069226,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "7-KZFP-wpcn7"
   },
   "outputs": [],
   "source": [
    "def extract_numerical_data(text):\n",
    "    return re.findall(r'\\d+\\.\\d+%?|\\$\\d+(?:,\\d{3})*(?:\\.\\d{1,2})?', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1738909222655,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "W9T-rm2QDq59",
    "outputId": "0643d952-3880-4397-bd94-3f203eaf9689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Extracted Numerical Data ===\n",
      "Test 1: Inflation rose by 3.5% in Q1.\n",
      "   â†’ Extracted Data: ['3.5%']\n",
      "\n",
      "Test 2: Apple's revenue hit $2,500,000 last year.\n",
      "   â†’ Extracted Data: ['$2,500,000']\n",
      "\n",
      "Test 3: Stock increased by 4.2% after a $1.5M buyback.\n",
      "   â†’ Extracted Data: ['4.2%', '$1.5']\n",
      "\n",
      "Test 4: The stock fell 0.85% after poor earnings.\n",
      "   â†’ Extracted Data: ['0.85%']\n",
      "\n",
      "Test 5: No major price movements were observed.\n",
      "   â†’ Extracted Data: []\n",
      "\n",
      "Test 6: Tesla stock jumped 5.75% after reporting $25.3 billion in revenue.\n",
      "   â†’ Extracted Data: ['5.75%', '$25.3']\n",
      "\n",
      "Test 7: Amazon's profit reached $1,250,000.50 this quarter.\n",
      "   â†’ Extracted Data: ['$1,250,000.50']\n",
      "\n",
      "Test 8: GDP grew 2.9% last quarter.\n",
      "   â†’ Extracted Data: ['2.9%']\n",
      "\n",
      "Test 9: New contract worth $50k is expected.\n",
      "   â†’ Extracted Data: ['$50']\n",
      "\n",
      "Test 10: Market fell by -1.2% today.\n",
      "   â†’ Extracted Data: ['1.2%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"Inflation rose by 3.5% in Q1.\",\n",
    "    \"Apple's revenue hit $2,500,000 last year.\",\n",
    "    \"Stock increased by 4.2% after a $1.5M buyback.\",\n",
    "    \"The stock fell 0.85% after poor earnings.\",\n",
    "    \"No major price movements were observed.\",\n",
    "    \"Tesla stock jumped 5.75% after reporting $25.3 billion in revenue.\",\n",
    "    \"Amazon's profit reached $1,250,000.50 this quarter.\",\n",
    "    \"GDP grew 2.9% last quarter.\",\n",
    "    \"New contract worth $50k is expected.\",\n",
    "    \"Market fell by -1.2% today.\"\n",
    "]\n",
    "\n",
    "# Running the test cases\n",
    "print(\"\\n=== Extracted Numerical Data ===\")\n",
    "for i, text in enumerate(test_cases):\n",
    "    result = extract_numerical_data(text)\n",
    "    print(f\"Test {i+1}: {text}\")\n",
    "    print(f\"   â†’ Extracted Data: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eQ8nAhyUKdU"
   },
   "source": [
    "Fetch news from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1738913679550,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "AR8TaTSGUpxv"
   },
   "outputs": [],
   "source": [
    "# Alpha Vantage API Configuration\n",
    "API_KEY = os.environ.get('ALPHA_KEY')\n",
    "BASE_URL = 'https://www.alphavantage.co/query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1738913930714,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "F-kyObNjUJY7"
   },
   "outputs": [],
   "source": [
    "# Step 12: Fetch Financial News from Alpha Vantage\n",
    "def fetch_alpha_vantage_news():\n",
    "    params = {\n",
    "        'function': 'NEWS_SENTIMENT',\n",
    "        'apikey': API_KEY,\n",
    "        'topics': 'technology, finance, energy',\n",
    "        'sort': 'LATEST',\n",
    "        'limit': 50\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None\n",
    "\n",
    "# Step 13: Fetch Financial News from Yahoo Finance\n",
    "def fetch_yahoo_finance_news():\n",
    "    yahoo_news_url = 'https://query1.finance.yahoo.com/v7/finance/news'\n",
    "    params = {'category': 'technology, finance, energy', 'count': 50}\n",
    "    response = requests.get(yahoo_news_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None\n",
    "\n",
    "# Main Execution: Fetch Data from Both Alpha Vantage and Yahoo Finance\n",
    "alpha_vantage_data = fetch_alpha_vantage_news()\n",
    "yahoo_finance_data = fetch_yahoo_finance_news()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1738913980790,
     "user": {
      "displayName": "Santhilata KV",
      "userId": "00256083586724494555"
     },
     "user_tz": 0
    },
    "id": "9cqfsmcHWYqa",
    "outputId": "de8b5bdb-b49e-478a-bd77-22c70e6e39df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429 Too Many Requests\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yahoo_finance_data = fetch_yahoo_finance_news()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGKROQTsXlgS"
   },
   "source": [
    "Duplicate Content Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqtNz6-TXBZJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_duplicates(df):\n",
    "    df['summary_hash'] = df['summary'].apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "    df.drop_duplicates(subset=['summary_hash'], keep='first', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FDokYtiYUeF"
   },
   "source": [
    "Identify Near-Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_41B2pYYP7o"
   },
   "outputs": [],
   "source": [
    "def identify_near_duplicates(df, threshold=0.9):\n",
    "    unique_articles = []\n",
    "    for idx, row in df.iterrows():\n",
    "        is_duplicate = False\n",
    "        for article in unique_articles:\n",
    "            similarity = difflib.SequenceMatcher(None, row['summary'], article['summary']).ratio()\n",
    "            if similarity > threshold:\n",
    "                is_duplicate = True\n",
    "                break\n",
    "        if not is_duplicate:\n",
    "            unique_articles.append(row)\n",
    "\n",
    "    # return the dataframe of unique articles\n",
    "    return pd.DataFrame(unique_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVK7UJdEY5kb"
   },
   "source": [
    "Context Preservation During Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ach8XDFpY67O"
   },
   "outputs": [],
   "source": [
    "def preserve_context(text):\n",
    "    context_terms = {\n",
    "        'stock': 'equity',\n",
    "        'bullish': 'positive market sentiment',\n",
    "        'bearish': 'negative market sentiment'\n",
    "    }\n",
    "    for term, replacement in context_terms.items():\n",
    "        text = text.replace(term, replacement)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30habAkWZHYb"
   },
   "source": [
    "Maintain Semantic Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9ix4G5dZAyW"
   },
   "outputs": [],
   "source": [
    "def maintain_semantics(text):\n",
    "    semantic_terms = {\n",
    "        'increase': 'rise',\n",
    "        'growth': 'rise',\n",
    "        'decrease': 'fall',\n",
    "        'decline': 'fall'\n",
    "    }\n",
    "    for term, replacement in semantic_terms.items():\n",
    "        text = text.replace(term, replacement)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_Ikuv9EZZ4_"
   },
   "source": [
    "Handling Ambiguous Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nabHziL6ZS8_"
   },
   "outputs": [],
   "source": [
    "def handle_ambiguity(text):\n",
    "    ambiguous_terms = {\n",
    "        'bullish': 'positive market sentiment',\n",
    "        'bearish': 'negative market sentiment',\n",
    "        'volatile': 'unstable market'\n",
    "    }\n",
    "    for term, replacement in ambiguous_terms.items():\n",
    "        text = text.replace(term, replacement)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP3GrH2JZOSo"
   },
   "source": [
    "Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q25qUmfWW5gD"
   },
   "outputs": [],
   "source": [
    "# Pipeline for Financial News Data\n",
    "def preprocess_news_data(news_data):\n",
    "    articles = news_data.get('feed', [])\n",
    "    cleaned_data = []\n",
    "\n",
    "    for article in articles:\n",
    "        title = clean_text(article.get('title', ''))\n",
    "        summary = clean_text(article.get('summary', ''))\n",
    "        source = article.get('source', 'Unknown')\n",
    "        sentiment_score = sia.polarity_scores(summary)['compound']\n",
    "\n",
    "        # Use contextual sentiment analysis to determine sentiment\n",
    "        contextual_sentiment_label, confidence = contextual_sentiment_analysis(summary)\n",
    "\n",
    "        # Choose sentiment from context or default to VADER-based sentiment\n",
    "        verified_sentiment = contextual_sentiment_label if confidence > 0.7 else \"Neutral\"\n",
    "\n",
    "        # Extract numerical data (e.g., stock prices, percentages)\n",
    "        numerical_data = extract_numerical_data(summary)\n",
    "\n",
    "        # Calculate credibility score based on the source\n",
    "        credibility_score = SOURCE_CREDIBILITY.get(source, 2)\n",
    "\n",
    "        # Step 3: Context Preservation\n",
    "        summary = preserve_context(summary)\n",
    "        summary = maintain_semantics(summary)  # Step 4: Maintain Semantic Relationships\n",
    "        summary = handle_ambiguity(summary)  # Step 5: Handle Ambiguity\n",
    "\n",
    "        cleaned_data.append({\n",
    "            'title': title,\n",
    "            'summary': summary,\n",
    "            'source': source,\n",
    "            'credibility_score': credibility_score,\n",
    "            'published_date': article.get('time_published', 'Unknown'),\n",
    "            'topics': \", \".join([topic.get('name', '') for topic in article.get('topics', []) if isinstance(topic, dict)]),\n",
    "            'alpha_vantage_sentiment': article.get('overall_sentiment_label', 'Neutral'),\n",
    "            'verified_sentiment': verified_sentiment,\n",
    "            'confidence': confidence,\n",
    "            'extracted_numerical_data': numerical_data\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for further analysis\n",
    "    df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "    # Remove duplicates and near-duplicates\n",
    "    df = remove_duplicates(df)\n",
    "    df = identify_near_duplicates(df)\n",
    "\n",
    "    # Handle missing data and mitigate bias\n",
    "    df = impute_missing_data(df)\n",
    "    df = detect_bias(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePajIAoJXIBT"
   },
   "source": [
    "Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5X1PaJJKEQW5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Combine both datasets\n",
    "if alpha_vantage_data and yahoo_finance_data:\n",
    "    combined_data = alpha_vantage_data['feed'] + yahoo_finance_data['items']\n",
    "    cleaned_df = preprocess_news_data({'feed': combined_data})\n",
    "    # Display the cleaned data\n",
    "    print(\"Cleaned Data Sample:\")\n",
    "    print(cleaned_df.head())\n",
    "    # Save the cleaned data to CSV\n",
    "    cleaned_df.to_csv('cleaned_financial_news_combined.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPlCYZl80pBMf01Ixsdb0f0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
